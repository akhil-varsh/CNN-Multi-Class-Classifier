{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Convert PyTorch Model to TensorFlow Lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 1: Convert PyTorch Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akhil\\Python_Projects\\CNN-Multi-Class-Classifier\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx\n",
      "  Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\akhil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\akhil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from onnx) (4.25.4)\n",
      "Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/14.5 MB 3.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.0/14.5 MB 3.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.3/14.5 MB 2.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.8/14.5 MB 1.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.1/14.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.4/14.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.6/14.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.9/14.5 MB 1.7 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 3.4/14.5 MB 1.7 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 3.4/14.5 MB 1.7 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 3.9/14.5 MB 1.6 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 4.2/14.5 MB 1.6 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 4.5/14.5 MB 1.6 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 5.0/14.5 MB 1.6 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 5.2/14.5 MB 1.6 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 5.5/14.5 MB 1.6 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 5.8/14.5 MB 1.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 6.3/14.5 MB 1.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 6.6/14.5 MB 1.6 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 7.1/14.5 MB 1.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 7.6/14.5 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 8.1/14.5 MB 1.7 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 8.9/14.5 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 9.4/14.5 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 9.7/14.5 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 9.7/14.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 10.2/14.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 10.5/14.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 10.7/14.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.0/14.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.5/14.5 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.8/14.5 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.1/14.5 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.3/14.5 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.6/14.5 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.1/14.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: onnx\n",
      "Successfully installed onnx-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\AppData\\Local\\Temp\\ipykernel_8620\\382827454.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('deep_cnn_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the DeepCNN model architecture\n",
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)  # 3 channels (RGB)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 128)  # Adjust these dimensions to match your model\n",
    "        self.fc2 = nn.Linear(128, 3)  # 3 classes: car, person, dog\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 28 * 28)  # Flatten the output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Step 1: Instantiate the model\n",
    "model = DeepCNN()\n",
    "\n",
    "# Step 2: Load the saved model's state dictionary\n",
    "model.load_state_dict(torch.load('deep_cnn_model.pth'))\n",
    "\n",
    "# Step 3: Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Create a dummy input matching the input size of your model (3x224x224 for an RGB image)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Step 5: Export the model to ONNX\n",
    "torch.onnx.export(model, dummy_input, 'deep_cnn_model.onnx', opset_version=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Nodes:\n",
      "Name: input.1, Shape: [dim_value: 1\n",
      ", dim_value: 3\n",
      ", dim_value: 224\n",
      ", dim_value: 224\n",
      "]\n",
      "\n",
      "Output Nodes:\n",
      "Name: 24, Shape: [dim_value: 1\n",
      ", dim_value: 3\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"deep_cnn_model.onnx\")\n",
    "\n",
    "# Get the graph from the model\n",
    "graph = model.graph\n",
    "\n",
    "# Print input nodes\n",
    "print(\"Input Nodes:\")\n",
    "for input in graph.input:\n",
    "    print(f\"Name: {input.name}, Shape: {input.type.tensor_type.shape.dim}\")\n",
    "\n",
    "# Print output nodes\n",
    "print(\"\\nOutput Nodes:\")\n",
    "for output in graph.output:\n",
    "    print(f\"Name: {output.name}, Shape: {output.type.tensor_type.shape.dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Try loading the ONNX model to ensure it's not corrupted\n",
    "try:\n",
    "    model = onnx.load(\"deep_cnn_model.onnx\")\n",
    "    onnx.checker.check_model(model)\n",
    "    print(\"ONNX model is valid!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading ONNX model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\AppData\\Local\\Temp\\ipykernel_14276\\2053466231.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('deep_cnn_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "from model import DeepCNN  # Assuming your model class is in deep_cnn_model.py\n",
    "\n",
    "# Load your model\n",
    "model = DeepCNN()\n",
    "model.load_state_dict(torch.load('deep_cnn_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Dummy input for the ONNX export (assuming input images are 3x224x224 RGB)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export the model to ONNX\n",
    "torch.onnx.export(model, dummy_input, 'model.onnx', opset_version=11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to check input & output nodes is to upload your model file in Netron (https://netron.app/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Nodes:\n",
      "Name: input.1, Shape: [dim_value: 1\n",
      ", dim_value: 3\n",
      ", dim_value: 224\n",
      ", dim_value: 224\n",
      "]\n",
      "\n",
      "Output Nodes:\n",
      "Name: 24, Shape: [dim_value: 1\n",
      ", dim_value: 3\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"model.onnx\")\n",
    "\n",
    "# Get the graph from the model\n",
    "graph = model.graph\n",
    "\n",
    "# Print input nodes\n",
    "print(\"Input Nodes:\")\n",
    "for input in graph.input:\n",
    "    print(f\"Name: {input.name}, Shape: {input.type.tensor_type.shape.dim}\")\n",
    "\n",
    "# Print output nodes\n",
    "print(\"\\nOutput Nodes:\")\n",
    "for output in graph.output:\n",
    "    print(f\"Name: {output.name}, Shape: {output.type.tensor_type.shape.dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tfa\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "print(tfa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
